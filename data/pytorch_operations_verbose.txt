## Creation Ops
torch.tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False) → Tensor
torch.sparse_coo_tensor(indices, values, size=None, *, dtype=None, device=None, pin_memory=False, requires_grad=False, check_invariants=None, is_coalesced=None) → Tensor
torch.sparse_csr_tensor(crow_indices, col_indices, values, size=None, *, dtype=None, device=None, pin_memory=False, requires_grad=False, check_invariants=None) → Tensor
torch.sparse_csc_tensor(ccol_indices, row_indices, values, size=None, *, dtype=None, device=None, pin_memory=False, requires_grad=False, check_invariants=None) → Tensor
torch.sparse_bsr_tensor(crow_indices, col_indices, values, size=None, *, dtype=None, device=None, pin_memory=False, requires_grad=False, check_invariants=None) → Tensor
torch.sparse_bsc_tensor(ccol_indices, row_indices, values, size=None, *, dtype=None, device=None, pin_memory=False, requires_grad=False, check_invariants=None) → Tensor
torch.asarray(obj: Any, *, dtype: Optional[dtype], device: Optional[DeviceLikeType], copy: Optional[bool] = None, requires_grad: bool = False) → Tensor
torch.as_tensor(data: Any, dtype: Optional[dtype] = None, device: Optional[DeviceLikeType]) → Tensor
torch.as_strided(input, size, stride, storage_offset=None) → Tensor
torch.from_file(filename, shared=None, size=0, *, dtype=None, layout=None, device=None, pin_memory=False)
torch.from_numpy(ndarray) → Tensor
torch.from_dlpack(ext_tensor) → Tensor
torch.frombuffer(buffer, *, dtype, count=-1, offset=0, requires_grad=False) → Tensor
torch.zeros(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor
torch.zeros_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor
torch.ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor
torch.ones_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor
torch.arange(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor
torch.range(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor
torch.linspace(start, end, steps, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor
torch.logspace(start, end, steps, base=10.0, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor
torch.eye(n, m=None, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor
torch.empty(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False, memory_format=torch.contiguous_format) → Tensor
torch.empty_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor
torch.empty_strided(size, stride, *, dtype=None, layout=None, device=None, requires_grad=False, pin_memory=False) → Tensor
torch.full(size, fill_value, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor
torch.full_like(input, fill_value, \*, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format) → Tensor
torch.quantize_per_tensor(input, scale, zero_point, dtype) → Tensor
torch.quantize_per_channel(input, scales, zero_points, axis, dtype) → Tensor
torch.dequantize(tensor) → Tensor
torch.complex(real, imag, *, out=None) → Tensor
torch.polar(abs, angle, *, out=None) → Tensor
torch.heaviside(input, values, *, out=None) → Tensor
## Indexing, Slicing, Joining, Mutating Ops
torch.adjoint(input: Tensor) → Tensor
torch.argwhere(input) → Tensor
torch.cat(tensors, dim=0, *, out=None) → Tensor
torch.concat(tensors, dim=0, *, out=None) → Tensor
torch.concatenate(tensors, axis=0, out=None) → Tensor
torch.conj(input) → Tensor
torch.chunk(input: Tensor, chunks: int, dim: int = 0) → Tuple[Tensor, ...]
torch.dsplit(input, indices_or_sections) → List of Tensors
torch.column_stack(tensors, *, out=None) → Tensor
torch.dstack(tensors, *, out=None) → Tensor
torch.gather(input, dim, index, *, sparse_grad=False, out=None) → Tensor
torch.hsplit(input, indices_or_sections) → List of Tensors
torch.hstack(tensors, *, out=None) → Tensor
torch.index_add(input: Tensor, dim: int, index: Tensor, source: Tensor, *, alpha: Union[Number, _complex] = 1, out: Optional[Tensor]) → Tensor
torch.index_copy(input: Tensor, dim: int, index: Tensor, source: Tensor, *, out: Optional[Tensor]) → Tensor
torch.index_reduce(input: Tensor, dim: int, index: Tensor, source: Tensor, reduce: str, *, include_self: bool = True, out: Optional[Tensor]) → Tensor
torch.index_select(input, dim, index, *, out=None) → Tensor
torch.masked_select(input, mask, *, out=None) → Tensor
torch.movedim(input, source, destination) → Tensor
torch.moveaxis(input, source, destination) → Tensor
torch.narrow(input, dim, start, length) → Tensor
torch.narrow_copy(input, dim, start, length, *, out=None) → Tensor
torch.nonzero(input, *, out=None, as_tuple=False) → LongTensor or tuple of LongTensors
torch.permute(input, dims) → Tensor
torch.reshape(input, shape) → Tensor
torch.row_stack(tensors, *, out=None) → Tensor
torch.select(input, dim, index) → Tensor
torch.scatter(input, dim, index, src) → Tensor
torch.diagonal_scatter(input, src, offset=0, dim1=0, dim2=1) → Tensor
torch.select_scatter(input, src, dim, index) → Tensor
torch.slice_scatter(input, src, dim=0, start=None, end=None, step=1) → Tensor
torch.scatter_add(input, dim, index, src) → Tensor
torch.scatter_reduce(input, dim, index, src, reduce, *, include_self=True) → Tensor
torch.split(tensor, split_size_or_sections, dim=0) -> tuple[torch.Tensor, …]
torch.squeeze(input: Tensor, dim: Optional[Union[int, List[int]]]) → Tensor
torch.stack(tensors, dim=0, *, out=None) → Tensor
torch.swapaxes(input, axis0, axis1) → Tensor
torch.swapdims(input, dim0, dim1) → Tensor
torch.t(input) → Tensor
torch.take(input, index) → Tensor
torch.take_along_dim(input, indices, dim=None, *, out=None) → Tensor
torch.tensor_split(input, indices_or_sections, dim=0) → List of Tensors
torch.tile(input, dims) → Tensor
torch.transpose(input, dim0, dim1) → Tensor
torch.unbind(input, dim=0) → seq
torch.unravel_index(indices, shape)
torch.unsqueeze(input, dim) → Tensor
torch.vsplit(input, indices_or_sections) → List of Tensors
torch.vstack(tensors, *, out=None) → Tensor
torch.where(condition, input, other, *, out=None) → Tensor
### Math operations

